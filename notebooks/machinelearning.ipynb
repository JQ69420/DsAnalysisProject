{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Scores for each fold: [0.71641791 0.70149254 0.73134328 0.83333333 0.78787879]\n",
      "Mean Accuracy: 0.7541\n",
      "Standard Deviation of Accuracy: 0.0492\n",
      "\n",
      "Precision Scores for each fold: [0.65       0.65714286 0.67567568 0.76315789 0.74285714]\n",
      "Mean Precision: 0.6978\n",
      "Standard Deviation of Precision: 0.0463\n",
      "\n",
      "Recall Scores for each fold: [0.83870968 0.74193548 0.80645161 0.93548387 0.83870968]\n",
      "Mean Recall: 0.8323\n",
      "Standard Deviation of Recall: 0.0626\n",
      "\n",
      "F1 Scores for each fold: [0.73239437 0.6969697  0.73529412 0.84057971 0.78787879]\n",
      "Mean F1: 0.7586\n",
      "Standard Deviation of F1: 0.0502\n",
      "\n",
      "Roc_auc Scores for each fold: [0.76344086 0.73073477 0.76388889 0.82073733 0.85437788]\n",
      "Mean Roc_auc: 0.7866\n",
      "Standard Deviation of Roc_auc: 0.0446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Define the Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# List of metrics to evaluate\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Evaluate each metric using cross-validation\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    if metric == 'roc_auc':\n",
    "        # For ROC AUC, we need to use the 'predict_proba' method, so set the pipeline to use probabilities\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc')\n",
    "    else:\n",
    "        # For other metrics, use standard class predictions\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring=metric)\n",
    "        \n",
    "    results[metric] = {\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for metric, values in results.items():\n",
    "    print(f\"\\n{metric.capitalize()} Scores for each fold: {values['scores']}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {values['mean']:.4f}\")\n",
    "    print(f\"Standard Deviation of {metric.capitalize()}: {values['std']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.73134328 0.74626866 0.73134328 0.83333333 0.78787879]\n",
      "Mean Accuracy: 0.77\n",
      "Standard Deviation: 0.04\n",
      "\n",
      "Final Test Set Accuracy: 0.67\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.61      0.67        36\n",
      "           1       0.62      0.74      0.68        31\n",
      "\n",
      "    accuracy                           0.67        67\n",
      "   macro avg       0.68      0.68      0.67        67\n",
      "weighted avg       0.68      0.67      0.67        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, features)]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std():.2f}\")\n",
    "\n",
    "# Split the data into training and test sets for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model on the training set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nFinal Test Set Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66        32\n",
      "           1       0.68      0.74      0.71        35\n",
      "\n",
      "    accuracy                           0.69        67\n",
      "   macro avg       0.69      0.68      0.68        67\n",
      "weighted avg       0.69      0.69      0.69        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ONLY FINAL GRADES ALL ANL's GROUPED\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "target = 'dropped out'\n",
    "\n",
    "# Function to map grades to categories\n",
    "def map_grades(grade):\n",
    "    if grade <= 3:\n",
    "        return 'Failed Miserably'\n",
    "    elif grade <= 5.4:\n",
    "        return 'Failed'\n",
    "    elif grade <= 7.5:\n",
    "        return 'Passed'\n",
    "    else:\n",
    "        return 'Passed Greatly'\n",
    "\n",
    "# Apply the mapping to each grade feature\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].apply(map_grades)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),  # Fill NA values with 'Missing'\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Convert categorical data to one-hot vectors\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, features)]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=500))  # Increase max_iter if needed\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69        32\n",
      "           1       0.71      0.77      0.74        35\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.72      0.71      0.71        67\n",
      "weighted avg       0.72      0.72      0.72        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ONLY FIRST CHANGE EXAM GRADES FROM EACH ANL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target for first-time exam grades\n",
    "features = ['anl1 fc grade', 'anl2 fc grade', 'anl3 fc grade', 'anl4 fc grade']\n",
    "target = 'dropped out'\n",
    "\n",
    "# Handle NaN or null by filling with 1\n",
    "X = df[features].fillna(1)\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Scale data to normalize\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, features)]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        31\n",
      "           1       0.73      0.73      0.73        37\n",
      "\n",
      "    accuracy                           0.71        68\n",
      "   macro avg       0.70      0.70      0.70        68\n",
      "weighted avg       0.71      0.71      0.71        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ALL FINAL GRADES + GENDER\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# Load the student performance data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Load the gender data\n",
    "gender_file = os.path.join(\"..\", \"data\", \"raw\", \"ANL1-2020-2021 attendance.xlsx\")\n",
    "gender_df = pd.read_excel(gender_file)\n",
    "\n",
    "# Merge the gender data with the main dataset\n",
    "df = df.merge(gender_df[['id', 'Gender']], on='id', how='left')\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target including the new 'Gender' feature\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'Gender']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['Gender']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),  # Fill missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Convert categorical data to one-hot vectors\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade with VT/DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70        32\n",
      "           1       0.72      0.74      0.73        35\n",
      "\n",
      "    accuracy                           0.72        67\n",
      "   macro avg       0.72      0.72      0.72        67\n",
      "weighted avg       0.72      0.72      0.72        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "VTDT_file = os.path.join(\"..\", \"data\", \"processed\", \"cleaned_students_vooropleiding.xlsx\")\n",
    "df_vtdt = pd.read_excel(VTDT_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Merge df with df_vtdt on 'id'\n",
    "df = pd.merge(df, df_vtdt[['id', 'voltijd deeltijd']], on='id', how='left')\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'voltijd deeltijd']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['voltijd deeltijd']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and obtain predicted probabilities for the positive class\n",
    "y_pred_proba = cross_val_predict(pipeline, X, y, cv=cv, method='predict_proba')\n",
    "\n",
    "# Only the probabilities of the positive class (class 1)\n",
    "y_pred_proba_positive_class = y_pred_proba[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred_proba_positive_class)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line (random classifier)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Cross-Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       178\n",
      "           1       0.70      0.83      0.76       155\n",
      "\n",
      "    accuracy                           0.75       333\n",
      "   macro avg       0.76      0.76      0.75       333\n",
      "weighted avg       0.77      0.75      0.75       333\n",
      "\n",
      "\n",
      "Confusion Matrix (Cross-Validation):\n",
      "[[122  56]\n",
      " [ 26 129]]\n",
      "Cross-Validation Results (Accuracy): [0.71641791 0.70149254 0.73134328 0.83333333 0.78787879]\n",
      "Mean Accuracy: 0.7540931705110809\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score ,confusion_matrix\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Perform cross-validation with predictions\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "y_pred_cv = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "\n",
    "# Evaluate cross-validation predictions\n",
    "print(\"Classification Report for Cross-Validation:\")\n",
    "print(classification_report(y, y_pred_cv))\n",
    "\n",
    "conf_matrix_cv = confusion_matrix(y, y_pred_cv)\n",
    "print(\"\\nConfusion Matrix (Cross-Validation):\")\n",
    "print(conf_matrix_cv)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "result = cross_val_score(pipeline, X, y, cv=cv)\n",
    "print(f'Cross-Validation Results (Accuracy): {result}')\n",
    "print(f'Mean Accuracy: {result.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobustScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26612/3286545020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Defining possible scalers to tune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mscalers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m numerical_transformer = Pipeline(steps=[\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobustScaler' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Define the Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],  # Regularization strength\n",
    "    'classifier__penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'classifier__solver': ['liblinear', 'lbfgs'],  # Solvers\n",
    "    'classifier__max_iter': [1000, 2000],  # Max number of iterations\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the model with hyperparameter tuning\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output the best hyperparameters and the best score\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best ROC AUC Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# List of metrics to evaluate\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Evaluate the best model using cross-validation for different metrics\n",
    "for metric in metrics:\n",
    "    if metric == 'roc_auc':\n",
    "        # For ROC AUC, we need to use the 'predict_proba' method, so set the pipeline to use probabilities\n",
    "        scores = cross_val_score(best_model, X, y, cv=cv, scoring='roc_auc')\n",
    "    else:\n",
    "        # For other metrics, use standard class predictions\n",
    "        scores = cross_val_score(best_model, X, y, cv=cv, scoring=metric)\n",
    "\n",
    "    print(f\"\\n{metric.capitalize()} Scores for each fold: {scores}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {scores.mean():.4f}\")\n",
    "    print(f\"Standard Deviation of {metric.capitalize()}: {scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}