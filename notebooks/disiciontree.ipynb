{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Scores for each fold: [0.67164179 0.64179104 0.67164179 0.66666667 0.71212121]\n",
      "Mean Accuracy: 0.6728\n",
      "Standard Deviation of Accuracy: 0.0226\n",
      "\n",
      "Precision Scores for each fold: [0.62857143 0.60606061 0.63636364 0.63636364 0.7       ]\n",
      "Mean Precision: 0.6415\n",
      "Standard Deviation of Precision: 0.0313\n",
      "\n",
      "Recall Scores for each fold: [0.70967742 0.64516129 0.67741935 0.67741935 0.67741935]\n",
      "Mean Recall: 0.6774\n",
      "Standard Deviation of Recall: 0.0204\n",
      "\n",
      "F1 Scores for each fold: [0.66666667 0.625      0.65625    0.65625    0.68852459]\n",
      "Mean F1: 0.6585\n",
      "Standard Deviation of F1: 0.0205\n",
      "\n",
      "Roc_auc Scores for each fold: [0.68100358 0.61648746 0.72132616 0.68248848 0.67695853]\n",
      "Mean Roc_auc: 0.6757\n",
      "Standard Deviation of Roc_auc: 0.0337\n",
      "\n",
      "Confusion Matrix (Decision Tree - Cross-Validation):\n",
      "[[119  59]\n",
      " [ 50 105]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline with Decision Tree\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# List of metrics to evaluate\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# Evaluate each metric using cross-validation\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    if metric == 'roc_auc':\n",
    "        # For ROC AUC, we need to use the 'predict_proba' method, so set the pipeline to use probabilities\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring='roc_auc')\n",
    "    else:\n",
    "        # For other metrics, use standard class predictions\n",
    "        scores = cross_val_score(pipeline, X, y, cv=cv, scoring=metric)\n",
    "        \n",
    "    results[metric] = {\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for metric, values in results.items():\n",
    "    print(f\"\\n{metric.capitalize()} Scores for each fold: {values['scores']}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {values['mean']:.4f}\")\n",
    "    print(f\"Standard Deviation of {metric.capitalize()}: {values['std']:.4f}\")\n",
    "\n",
    "# Get cross-validation predictions\n",
    "y_pred_cv = cross_val_predict(pipeline, X, y, cv=cv)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred_cv)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix (Decision Tree - Cross-Validation):\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "\n",
      "Best Parameters: {'classifier__criterion': 'entropy', 'classifier__max_depth': 3, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}\n",
      "Best ROC AUC Score: 0.7757\n",
      "\n",
      "Accuracy Scores for the Best Model: [0.73134328 0.68656716 0.74626866 0.84848485 0.8030303 ]\n",
      "Mean Accuracy: 0.7631\n",
      "Standard Deviation of Accuracy: 0.0566\n",
      "\n",
      "Precision Scores for the Best Model: [0.65116279 0.63157895 0.68421053 0.75609756 0.75      ]\n",
      "Mean Precision: 0.6946\n",
      "Standard Deviation of Precision: 0.0506\n",
      "\n",
      "Recall Scores for the Best Model: [0.90322581 0.77419355 0.83870968 1.         0.87096774]\n",
      "Mean Recall: 0.8774\n",
      "Standard Deviation of Recall: 0.0747\n",
      "\n",
      "F1 Scores for the Best Model: [0.75675676 0.69565217 0.75362319 0.86111111 0.80597015]\n",
      "Mean F1: 0.7746\n",
      "Standard Deviation of F1: 0.0556\n",
      "\n",
      "Roc_auc Scores for the Best Model: [0.75044803 0.68145161 0.79793907 0.83041475 0.81843318]\n",
      "Mean Roc_auc: 0.7757\n",
      "Standard Deviation of Roc_auc: 0.0545\n",
      "\n",
      "Confusion Matrix (Decision Tree - Best Model):\n",
      "[[118  60]\n",
      " [ 19 136]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "student_file = os.path.join(\"..\", \"data\", \"processed\", \"Merged_Final_File_Updated.xlsx\")\n",
    "df = pd.read_excel(student_file)\n",
    "\n",
    "# Map dependent variable 'dropped out' to binary\n",
    "df['dropped out'] = df['dropped out'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# Define features and target\n",
    "features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade', 'education_level']\n",
    "target = 'dropped out'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = ['anl1 final grade', 'anl2 final grade', 'anl3 final grade', 'anl4 final grade']\n",
    "categorical_features = ['education_level']\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=1)),  # Fill NA values with 1\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the pipeline with Decision Tree\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the Stratified K-Fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'classifier__criterion': ['gini', 'entropy', 'log_loss'],  # Criteria for splitting\n",
    "    'classifier__max_depth': [3, 5, 10, None],                # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],              # Minimum samples required to split an internal node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],                # Minimum samples required to be at a leaf node\n",
    "    'classifier__max_features': [None, 'sqrt', 'log2']        # Number of features to consider when splitting\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # Use ROC AUC as the primary metric\n",
    "    cv=cv,\n",
    "    n_jobs=-1,          # Use all available CPU cores\n",
    "    verbose=2           # Verbosity level\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"Best ROC AUC Score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Evaluate the best model on additional metrics\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "results = {}\n",
    "for metric in metrics:\n",
    "    if metric == 'roc_auc':\n",
    "        scores = cross_val_score(best_pipeline, X, y, cv=cv, scoring='roc_auc')\n",
    "    else:\n",
    "        scores = cross_val_score(best_pipeline, X, y, cv=cv, scoring=metric)\n",
    "        \n",
    "    results[metric] = {\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "\n",
    "# Print results for each metric\n",
    "for metric, values in results.items():\n",
    "    print(f\"\\n{metric.capitalize()} Scores for the Best Model: {values['scores']}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {values['mean']:.4f}\")\n",
    "    print(f\"Standard Deviation of {metric.capitalize()}: {values['std']:.4f}\")\n",
    "\n",
    "# Get cross-validation predictions\n",
    "y_pred_cv = cross_val_predict(best_pipeline, X, y, cv=cv)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred_cv)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"\\nConfusion Matrix (Decision Tree - Best Model):\")\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
